{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "a377c2a0",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Melanoma and tumor-infiltrating lymphocyte examples\n",
    "\n",
    "This notebook prepares Perturb-seq datasets from [Frangieh et al.](https://www.nature.com/articles/s41588-021-00779-1), a project on melanoma immune checkpoint inhibitor resistance. CRISPR knockouts of ~250 genes were applied to melanoma cells, and then the melanoma cells were treated in a variety of ways, including control, interferon gamma, and co-culture with tumor infiltrating lymphocytes. The idea is to see what mutations in melanoma might protect the melanoma from the lymphocytes. The paper included low-dimensional readouts based on melanoma survival and also perturb-seq readouts, which included mostly melanoma with minimal T cell contamination. Here we tidy the dataset and carry out a simple exploration in scanpy. \n",
    "\n",
    "This handling of the Frangieh data aims to understand the effect of different preprocessing on GRN inference, particularly tailored towards benchmarking DCDFG (Lopez et al. 2022). Overall, this notebook will generate 4 versions of the datasets. Each latter version consistutes of more processing than its predecessor. Specifically, expression_quantified is exactly the same as what Lopez et al. did. V2 is based on expression_quantified, except an additional standard scRNA preprocessing and a regime filtering (more details see below). V3 is the pseudobulk version of the V2. V4 is like V1, but cell cycle is regressed out. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5207ee00",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import regex as re\n",
    "import os\n",
    "import shutil\n",
    "import sys\n",
    "import importlib\n",
    "import matplotlib.colors as colors\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scanpy as sc\n",
    "import seaborn as sns\n",
    "import scipy as sp\n",
    "from scipy.stats import spearmanr as spearmanr\n",
    "from scipy.stats import pearsonr\n",
    "from IPython.display import set_matplotlib_formats\n",
    "set_matplotlib_formats('svg')\n",
    "import itertools as it\n",
    "import anndata\n",
    "import gc\n",
    "\n",
    "\n",
    "import functools\n",
    "from scipy.stats import f_oneway\n",
    "from statsmodels.stats.multitest import multipletests\n",
    "from statsmodels.stats.oneway import anova_oneway\n",
    "from sklearn.metrics import mutual_info_score\n",
    "import time\n",
    "from collections import Counter\n",
    "\n",
    "\n",
    "# local\n",
    "import importlib\n",
    "import sys\n",
    "sys.path.append(\"setup\")\n",
    "import ingestion\n",
    "importlib.reload(ingestion)\n",
    "\n",
    "#      visualization settings\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = [6, 4.5]\n",
    "plt.rcParams[\"savefig.dpi\"] = 300\n",
    "\n",
    "# I prefer to specify the working directory explicitly.\n",
    "os.chdir(\"/home/ekernf01/Desktop/jhu/research/projects/perturbation_prediction/cell_type_knowledge_transfer/perturbation_data\")\n",
    "\n",
    "# Universal\n",
    "geneAnnotationPath = \"../accessory_data/gencode.v35.annotation.gtf.gz\"       # Downloaded from https://www.gencodegenes.org/human/release_35.html\n",
    "humanTFPath = \"../accessory_data/humanTFs.csv\"                               # Downloaded from http://humantfs.ccbr.utoronto.ca/download.php\n",
    "humanEpiPath = \"../accessory_data/epiList.csv\"                               # Downloaded from https://epifactors.autosome.org/description \n",
    "cellCyclePath= \"../accessory_data/regev_lab_cell_cycle_genes.txt\"\n",
    "\n",
    "# Dataset-specific\n",
    "rawDataPath  = \"not_ready/frangieh/RNA_expression.csv.gz\"\n",
    "rawH5ADPath  = \"not_ready/frangieh/RNA_expression.h5ad.gz\"\n",
    "cellMetaPath = \"not_ready/frangieh/all_sgRNA_assignments.txt\"   \n",
    "cellConditionPath = \"not_ready/frangieh/RNA_metadata.csv\"\n",
    "perturbEffectTFOnlyPath = \"../accessory_data/frangiehTFOnly.csv\"                        # a path to store temp file\n",
    "perturbEffectFullTranscriptomePath = \"../accessory_data/frangiehFullTranscriptome.csv\"  # a path to store temp file\n",
    "\n",
    "finalDataFileFolder = \"perturbations/frangieh\"\n",
    "finalDataFilePath   = \"perturbations/frangieh/test.h5ad\"\n",
    "\n",
    "dataset_name = \"frangieh\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "869bdb58-3d9a-49dd-8f39-08e667ddf0e5",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Frangieh Version 1 (exactly following Lopez et al.)\n",
    "\n",
    "We first convert normalized data back to raw counts, and then we remove cells having less than 500 genes and and genes occurring in less than 500 cells. We also scan through predicted guide RNA assignments and remove all perturbed but not measured gene assignments. Remaining perturbations are encoded numerically, stored in the field `regime`.\n",
    "\n",
    "We can rank all genes and kept top 1000 highly variable ones following the procedure Lopez et al. did in DCDFG repo (to ensure maximal level of similarity). Please note that the top N HVG procedure actually preserves less than 1000 genes (see code in this section for more details). We do split the dataset into 3 subsets, according to the experimental culture condition. Each version 1 dataset ends up with ~60000 instances and ~960 genes."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "275b88c7",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Load expression data & set up cell metadata (including `sgRNA`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07d803df",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if os.path.exists(rawH5ADPath):\n",
    "    expression_quantified = sc.read_h5ad(rawH5ADPath)\n",
    "else:\n",
    "    expression_quantified = sc.read_csv(rawDataPath)\n",
    "    expression_quantified.write_h5ad(rawH5ADPath, compression=\"gzip\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57ad2a39-387d-4e3e-bfcc-5d0e31646aa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "expression_quantified.X = sp.sparse.csr_matrix(expression_quantified.X)\n",
    "expression_quantified = expression_quantified.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1332cfd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "cell_meta  = pd.read_csv(cellMetaPath)\n",
    "cell_meta2 = pd.read_csv(cellConditionPath, skiprows=[1])\n",
    "cell_meta  = cell_meta.merge(cell_meta2, left_on=\"Cell\", right_on=\"NAME\")\n",
    "cell_meta.index = cell_meta[\"Cell\"].tolist()\n",
    "expression_quantified.obs = cell_meta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27e2eec4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "guides = functools.reduce(lambda a,b: a.union(b), [set(str(s).split(\",\")) for s in expression_quantified.obs[\"sgRNAs\"]])\n",
    "def get_target(guide):\n",
    "    return re.sub(\"_[0-9]*$\", \"\", guide) \n",
    "def is_control(target):\n",
    "    return \"SITE\" in target\n",
    "human_tfs = pd.read_csv(humanTFPath)\n",
    "human_tfs = human_tfs.loc[human_tfs[\"Is TF?\"]==\"Yes\",:]\n",
    "np.array(list(set([get_target(g) for g in guides]).intersection(human_tfs[\"HGNC symbol\"])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8199f0fa-22bd-45e6-a213-74129762d927",
   "metadata": {},
   "outputs": [],
   "source": [
    "guide_info = pd.read_csv(cellMetaPath, index_col=0)\n",
    "guide_info = guide_info.replace(np.nan, '', regex=True)\n",
    "expression_quantified.obs[\"sgRNAs\"] = guide_info[\"sgRNAs\"].astype(str)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "fdf22c96-04ad-4d77-a781-977df6d7012b",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Adjust back to raw count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cd73670-a307-4639-94f0-1ca25f461bc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "expression_quantified.obs[\"MOI\"] = expression_quantified.obs[\"MOI\"].astype(np.int32)\n",
    "expression_quantified.obs[\"UMI_count\"] = expression_quantified.obs[\"UMI_count\"].astype(np.double)\n",
    "\n",
    "# de-normalize and round up\n",
    "def recover_raw_counts(adata, total = None):\n",
    "    if total is None:\n",
    "        total = np.expm1(adata.X[0, :]).sum()\n",
    "        total = 10**round(np.log10(total))\n",
    "        print(f\"Data appear to be scaled to a total of {total}\")\n",
    "    norm_factor = adata.obs[\"UMI_count\"].values / total\n",
    "    Z = sp.sparse.diags(norm_factor).dot(np.expm1(adata.X))\n",
    "    fraction_far_off = np.mean(np.abs(Z.data - np.rint(Z.data)) > 0.01)\n",
    "    assert fraction_far_off < 0.05, f\"Reverse transform returned non-integer values in {fraction_far_off} proportion of values.\"\n",
    "    Z.data = np.rint(Z.data)\n",
    "    return anndata.AnnData(X=Z, obs = adata.obs, var = adata.var)\n",
    "\n",
    "expression_quantified.X = recover_raw_counts(expression_quantified).X"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "cd7265dc-5587-4afd-a6ab-292d40a91c88",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Filter out genes and cells w/ low count "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92bcf01c-9b34-41a3-ab51-defa11b7a5e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.pp.filter_cells(expression_quantified, min_genes=500)\n",
    "sc.pp.filter_genes(expression_quantified, min_cells=500)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "d2a6cc7c",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Label each cell with perturbations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bb9da4f-20d9-4e8c-8be5-cfbd9f85f18a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def assign_targets(adata):\n",
    "    # check gene sets and ensure matching with measurements\n",
    "    err = 0\n",
    "    ind = []\n",
    "    obs_genes = {}\n",
    "    unfound_genes = {}\n",
    "    targets = []\n",
    "    for index, row in adata.obs.iterrows():\n",
    "        current_target = []\n",
    "        if row[\"sgRNAs\"] != \"\":\n",
    "            # get all guides in cells\n",
    "            sg = row[\"sgRNAs\"].split(\",\")\n",
    "            # get gene name by stripping guide specific info\n",
    "            sg_genes = [guide.rsplit(\"_\", maxsplit=1)[0] for guide in sg]\n",
    "            for gene in sg_genes:\n",
    "                if gene in adata.var.index:\n",
    "                    # gene is found\n",
    "                    current_target += [gene]\n",
    "                    if gene not in obs_genes:\n",
    "                        obs_genes[gene] = 1\n",
    "                    else:\n",
    "                        obs_genes[gene] += 1\n",
    "                else:\n",
    "                    if gene not in unfound_genes:\n",
    "                        unfound_genes[gene] = 1\n",
    "                    else:\n",
    "                        unfound_genes[gene] += 1\n",
    "        # end gene list\n",
    "        targets += [\",\".join(current_target)]\n",
    "\n",
    "    return targets\n",
    "\n",
    "expression_quantified.obs[\"targets\"]  = assign_targets(expression_quantified)\n",
    "print(expression_quantified.obs[\"targets\"].value_counts(dropna = False))\n",
    "expression_quantified.obs[\"targets\"].value_counts(dropna = False).value_counts(normalize=True).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f723f9c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "expression_quantified.obs[\"perturbation\"] = expression_quantified.obs['targets']\n",
    "expression_quantified.obs[\"is_control\"]   = [t in {\"nan\", \"\"} for t in expression_quantified.obs['targets']]\n",
    "expression_quantified.obs[\"is_control_int\"]   = expression_quantified.obs[\"is_control\"].astype(int)\n",
    "expression_quantified.obs[\"sgRNA\"] = expression_quantified.obs.sgRNAs.apply(\n",
    "    lambda x: \",\".join([n for n in x.split(\",\") \n",
    "                        if not is_control(n) and \n",
    "                        n.split(\"_\")[0] in expression_quantified.var.index])\n",
    ")\n",
    "expression_quantified.obs.sgRNA[expression_quantified.obs.is_control] = \"is_control\"\n",
    "expression_quantified.obs[\"is_control\"].value_counts(dropna = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf5e32d2-281f-4d36-a3de-1fbee3918a5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" \n",
    "sgRNAs: raw metadata (target gene + guide info)\n",
    "sgRNA : sgRNAs but not measuread target genes & SITEs are removed, controls are labeled \"is_control\"\n",
    "targets == perturbation: sgRNA but without guide info nor controls\n",
    "\"\"\"\n",
    "expression_quantified.obs[[\"sgRNAs\", \"sgRNA\", \"targets\", \"perturbation\"]].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b6a0868-c574-4235-8dd0-3d25eb28c1a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "perturbed = expression_quantified.obs.targets.apply(lambda x: x.split(\",\"))\n",
    "perturbed = set([i for j in perturbed for i in j if i])\n",
    "print(len(perturbed))\n",
    "present   = perturbed & set(expression_quantified.var_names)\n",
    "print(len(present  ))\n",
    "present_bool = np.array([i in present for i in expression_quantified.var_names], dtype=bool)\n",
    "expression_quantified.var[\"targeted\"] = present_bool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43cebca7-14d3-4d61-afec-3b3bcdc1a57c",
   "metadata": {},
   "outputs": [],
   "source": [
    "perturbed_not_measured_obs = np.full(expression_quantified.n_obs, False)\n",
    "for idx, targets in enumerate(expression_quantified.obs.targets):\n",
    "    if expression_quantified.obs.is_control[idx]:\n",
    "        continue\n",
    "    if any([target not in present for target in targets.split(\",\")]):\n",
    "        perturbed_not_measured_obs[idx] = True\n",
    "expression_quantified.obs[\"instance_with_perturbed_not_measured_genes\"] = perturbed_not_measured_obs\n",
    "print(expression_quantified)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41659d26-dd01-4b6e-9c53-3708f57c8b36",
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.pp.normalize_total(expression_quantified, target_sum=1e5)\n",
    "sc.pp.log1p(expression_quantified)\n",
    "sc.pp.highly_variable_genes(\n",
    "    expression_quantified, \n",
    "    flavor='seurat_v3', \n",
    "    n_top_genes=expression_quantified.n_vars,\n",
    "    span=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc62918f-6ada-4f31-8cdf-c3ea4ca7bdae",
   "metadata": {},
   "outputs": [],
   "source": [
    "expression_quantified.obs[\"regimes\"] = np.unique(expression_quantified.obs.targets, return_inverse=True)[1]\n",
    "for condition in set(expression_quantified.obs.condition):\n",
    "    subset = expression_quantified[expression_quantified.obs.condition == condition].copy()\n",
    "    # Very low-expressed genes were already filtered, except that the subsetting may create more.\n",
    "    sc.pp.filter_genes(subset, min_cells=0)\n",
    "    \n",
    "    \"\"\" Add additional metadata to ensure passing dataset validity check \"\"\"\n",
    "    print(f\"{condition:>15} expression_quantified ends up with {subset.n_obs:>6} instances and {subset.n_vars:>5} genes.\")\n",
    "    subset.obs[\"spearmanCorr\"]          = 0.0\n",
    "    subset.uns[\"perturbations_overlap\"] = True\n",
    "    subset.obs[\"perturbation_type\"]     = \"knockout\" \n",
    "    subset.obs[\"expression_level_after_perturbation\"] = [\",\".join([\"0\"]*len(targets.split(\",\"))) for targets in subset.obs[\"perturbation\"] ]\n",
    "    subset.obs.loc[(subset.obs.is_control | subset.obs.instance_with_perturbed_not_measured_genes), \n",
    "                   \"expression_level_after_perturbation\"] = np.nan\n",
    "    \n",
    "    perturbed_genes = set.union(*[set(p.split(\",\")) for p in subset.obs[\"perturbation\"]])\n",
    "    perturbed_and_measured_genes = perturbed_genes.intersection(subset.var.index)\n",
    "    perturbed_but_not_measured_genes = perturbed_genes.difference(subset.var.index)\n",
    "    subset.uns[\"perturbed_and_measured_genes\"]     = list(perturbed_and_measured_genes)\n",
    "    subset.uns[\"perturbed_but_not_measured_genes\"] = list(perturbed_but_not_measured_genes)\n",
    "    subset.raw = recover_raw_counts(subset) # We do this one at a time to save RAM\n",
    "    os.makedirs(f\"perturbations/{dataset_name}_{condition}_v1\", exist_ok=True)\n",
    "    subset.write_h5ad(f\"perturbations/{dataset_name}_{condition}_v1/test.h5ad\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "877dcd2f",
   "metadata": {},
   "source": [
    "### Frangieh Version 4 \n",
    "\n",
    "This is just like version 1, but with cell cycle regressed out. Sorry the versions are out of order; this is what made sense as the project developed, and versions 2 and 3 follow shortly in this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfc399c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "expression_quantified.obs[\"regimes\"] = np.unique(expression_quantified.obs.targets, return_inverse=True)[1]\n",
    "for condition in set(expression_quantified.obs.condition):\n",
    "    subset = expression_quantified[expression_quantified.obs.condition == condition].copy()\n",
    "    # Very low-expressed genes were already filtered, except that the subsetting may create more.\n",
    "    sc.pp.filter_genes(subset, min_cells=0)\n",
    "    \n",
    "    subset.raw = recover_raw_counts(subset) # We do this one at a time to save RAM\n",
    "\n",
    "    # Regress out CC\n",
    "    cc_genes = pd.read_csv(cellCyclePath, header = None)[0]\n",
    "    sc.tl.score_genes_cell_cycle(subset, s_genes=cc_genes[:43], g2m_genes=cc_genes[43:])\n",
    "    sc.pp.regress_out(subset, keys = ['S_score', 'G2M_score'])\n",
    "\n",
    "\n",
    "    \"\"\" Add additional metadata to ensure passing dataset validity check \"\"\"\n",
    "    print(f\"{condition:>15} expression_quantified ends up with {subset.n_obs:>6} instances and {subset.n_vars:>5} genes.\")\n",
    "    subset.obs[\"spearmanCorr\"]          = 0.0\n",
    "    subset.uns[\"perturbations_overlap\"] = True\n",
    "    subset.obs[\"perturbation_type\"]     = \"knockout\" \n",
    "    subset.obs[\"expression_level_after_perturbation\"] = [\",\".join([\"0\"]*len(targets.split(\",\"))) for targets in subset.obs[\"perturbation\"] ]\n",
    "    subset.obs.loc[(subset.obs.is_control | subset.obs.instance_with_perturbed_not_measured_genes), \n",
    "                   \"expression_level_after_perturbation\"] = np.nan\n",
    "    \n",
    "    perturbed_genes = set.union(*[set(p.split(\",\")) for p in subset.obs[\"perturbation\"]])\n",
    "    perturbed_and_measured_genes = perturbed_genes.intersection(subset.var.index)\n",
    "    perturbed_but_not_measured_genes = perturbed_genes.difference(subset.var.index)\n",
    "    subset.uns[\"perturbed_and_measured_genes\"]     = list(perturbed_and_measured_genes)\n",
    "    subset.uns[\"perturbed_but_not_measured_genes\"] = list(perturbed_but_not_measured_genes)\n",
    "    os.makedirs(f\"perturbations/{dataset_name}_{condition}_v4\", exist_ok=True)\n",
    "    subset.write_h5ad(f\"perturbations/{dataset_name}_{condition}_v4/test.h5ad\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "d337f543",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Frangieh Version 2\n",
    "\n",
    "In addition to all the processing performed for v1, we prefer to add more conservative filters, including removal of doublets, cells with high mitochondrial/ribosome gene content. (However, mito and ribo genes are NOT removed.)\n",
    "\n",
    "Additional, many cells are infected by more than one lentivirus and therefore potentially have multiple perturbed genes. Because cells with high MOIs are rare (mean MOI ~= 1.3) and have few duplicates, to ease the causal inference problem at hand, version 2 datasets kept only cells with 1 predicted perturbed gene and at least 50 cells (across all guide RNAs).\n",
    "\n",
    "Version 2 dataset ends up with ~40k instances and ~15k (all ranked, ranking was performed during version 1 processing). Thus, if one were to perform Top N HVG procedure as Lopez et al. did, they can obtain a dataset with the same set of genes (roughly, because the procedure also removes genes that are 0 across all instances, removal of instances may result in certain genes become all 0)."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b20715b5-b199-48f9-a8fe-d0a4af88242d",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "#### Single-Cell Standard QC filters "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c698821e-8e8b-4556-9a47-218a32072aec",
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.pl.highest_expr_genes(expression_quantified, n_top=30, palette=\"Blues\", width=.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc4e89da-88ce-450b-9071-ce9ce2c2f1bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "expression_quantified.var['mt']   = expression_quantified.var_names.str.startswith((\"MT-\"))\n",
    "expression_quantified.var['ribo'] = expression_quantified.var_names.str.startswith((\"RPS\",\"RPL\"))\n",
    "expression_quantified.var['mt'].sum(), expression_quantified.var['ribo'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b367793-b341-45c3-9715-b439ce1daeeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.pp.calculate_qc_metrics(expression_quantified, qc_vars=['ribo', 'mt'], log1p=False, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f5af9aa-a2f6-4b2b-b4ff-7edd45873ced",
   "metadata": {},
   "outputs": [],
   "source": [
    "axs = sc.pl.violin(expression_quantified, ['n_genes_by_counts', \n",
    "                                           'total_counts', \n",
    "                                           'pct_counts_mt', \n",
    "                                           'pct_counts_ribo', \n",
    "                                           'pct_counts_in_top_50_genes'], \n",
    "                   jitter=0.5, multi_panel=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64d817e9-d20d-45e1-9bf5-58cdbfd06db5",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1,1,figsize=(2,2))\n",
    "sc.pl.scatter(expression_quantified, x='total_counts', y='n_genes_by_counts', ax=ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35bee240-4c23-4a79-8ee3-56788a66381e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Number of cells: \", expression_quantified.n_obs)\n",
    "\n",
    "# figure out the total counts == 99th percentile\n",
    "thresh = np.percentile(expression_quantified.obs['total_counts'], 99)\n",
    "print(\"99th percentile: \", thresh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78c8bc46-18c6-4379-b368-6c765c6eed6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter for % mt & % ribo\n",
    "expression_quantified = expression_quantified[((expression_quantified.obs['total_counts']    < thresh) &\n",
    "                                               (expression_quantified.obs[\"total_counts\"]    >= 6000)  & \n",
    "                                               (expression_quantified.obs[\"pct_counts_in_top_50_genes\"] <= 30) & \n",
    "                                               (expression_quantified.obs['pct_counts_mt']   < 10)     & \n",
    "                                               (expression_quantified.obs['pct_counts_ribo'] < 20)), :]\n",
    "expression_quantified = expression_quantified.copy()\n",
    "print(\"Number of cells: \", expression_quantified.n_obs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f201675-2679-40b3-80a5-39dfc1b86a6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" To verify the outcome of filtering cells \"\"\"\n",
    "sc.pp.calculate_qc_metrics(expression_quantified, qc_vars=['ribo', 'mt'], percent_top=None, log1p=False, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c3ecb6d-2df7-4f1c-bade-da9705c04024",
   "metadata": {},
   "outputs": [],
   "source": [
    "axs = sc.pl.violin(expression_quantified, ['n_genes_by_counts', \n",
    "                                           'total_counts', \n",
    "                                           'pct_counts_mt', \n",
    "                                           'pct_counts_ribo', \n",
    "                                           'pct_counts_in_top_50_genes'], \n",
    "                   jitter=0.4, multi_panel=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "721fe529-d297-4b4e-8f29-e047db209b73",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1,1,figsize=(2,2))\n",
    "sc.pl.scatter(expression_quantified, x='total_counts', y='n_genes_by_counts', ax=ax)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "d4585fd4-85bc-4055-acc9-fdefb39cb904",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "#### Regime Filtering (more than 1 MOI or less than 50 cells)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bf5c230-f8ab-4d86-887f-2e77834d3cd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "grp = expression_quantified.obs.groupby([\"condition\", \"perturbation\"])\n",
    "keep = []\n",
    "for k,v in grp.indices.items():\n",
    "    if len(k[1].split(\",\")) > 1 or len(v) < 50:\n",
    "        continue\n",
    "    keep.append(k)\n",
    "    profile = np.squeeze(np.array(expression_quantified.X[v,:].sum(axis=0)))\n",
    "print(f\"We are keeping {len(keep)} culture condition-target gene combination (not distinguishing different sgRNA)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7355891-2c55-4bec-bfa3-0612d6dfc52e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "keeprow = [grp.indices[k] for k in keep]\n",
    "keeprow = [i for j in keeprow for i in j]\n",
    "print(f\"We are keeping {len(keep)} condition-target combo, \" \\\n",
    "      f\"totaling {len(keeprow)} cells.\")\n",
    "expression_quantified = expression_quantified[keeprow].copy()\n",
    "expression_quantified.obs[\"perturbation\"] = expression_quantified.obs[\"perturbation\"].astype(str)\n",
    "print(expression_quantified)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6afe61fe-173c-4b8a-930d-520e4186de6f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "expression_quantified\n",
    "for condition in set(expression_quantified.obs.condition):\n",
    "    subset = expression_quantified[expression_quantified.obs.condition == condition].copy()\n",
    "    \n",
    "    subset.obs[\"regimes\"] = np.unique(subset.obs.targets, return_inverse=True)[1]    \n",
    "    print(f\"{condition:>15} v2 ends up with {subset.n_obs:>6} instances and {subset.n_vars:>5} genes.\")\n",
    "    subset.obs[\"spearmanCorr\"]          = 0.0\n",
    "    subset.uns[\"perturbations_overlap\"] = True\n",
    "    subset.obs[\"perturbation_type\"]     = \"knockout\" \n",
    "    subset.obs[\"expression_level_after_perturbation\"] = [\",\".join([\"0\"]*len(targets.split(\",\"))) for targets in subset.obs[\"perturbation\"] ]\n",
    "    subset.obs.loc[(subset.obs.is_control | subset.obs.instance_with_perturbed_not_measured_genes), \n",
    "                   \"expression_level_after_perturbation\"] = np.nan\n",
    "\n",
    "    perturbed_genes = set.union(*[set(p.split(\",\")) for p in subset.obs[\"perturbation\"]])\n",
    "    perturbed_and_measured_genes = perturbed_genes.intersection(subset.var.index)\n",
    "    perturbed_but_not_measured_genes = perturbed_genes.difference(subset.var.index)\n",
    "    subset.uns[\"perturbed_and_measured_genes\"]     = list(perturbed_and_measured_genes)\n",
    "    subset.uns[\"perturbed_but_not_measured_genes\"] = list(perturbed_but_not_measured_genes)\n",
    "    subset.raw = recover_raw_counts(subset) # We do this one at a time to save RAM\n",
    "    os.makedirs(f\"perturbations/{dataset_name}_{condition}_v2\", exist_ok=True)\n",
    "    subset.write_h5ad(f\"perturbations/{dataset_name}_{condition}_v2/test.h5ad\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "80292c57-85a5-471f-b103-5263a3be1630",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Frangieh Version 3\n",
    "\n",
    "On top of V2, cells with the same culture condition and the same guide RNAs are summed (raw counts) and normalized. The cells with the same `regime` but different sgRNAs remain separate (thus, each `regime` may end up with multiple meta-cells post aggregation) \n",
    "\n",
    "After aggregation, the version 3 dataset ends up with ~600 instances and ~15k genes. The gene ranking from version 1 is kept, so that in v1, v2, or v3, if the top N genes are selected, the resulting list will be the same. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f146680f-2041-4bca-a306-cc59ad2de174",
   "metadata": {},
   "outputs": [],
   "source": [
    "grp = expression_quantified.obs.groupby([\"condition\", \"perturbation\", \"sgRNA\"])\n",
    "newObs = pd.DataFrame([[k[0], k[1], k[1], k[2], \n",
    "                        True if k[2] == \"is_control\" else False, \n",
    "                        1 if k[2] == \"is_control\" else 0] \n",
    "                       for k,v in grp.indices.items()],\n",
    "                      columns=[\"condition\", \"perturbation\", \"targets\", \"sgRNA\", \"is_control\", \"is_control_int\"])\n",
    "expression_quantified.X = recover_raw_counts(expression_quantified).X\n",
    "newX   = np.squeeze(np.array([\n",
    "    expression_quantified.X[grp.indices[(r[0], r[1], r[3])],:].sum(axis=0).copy() \n",
    "    for idx, r in newObs.iterrows()\n",
    "]))\n",
    "pseudobulk = sc.AnnData(newX,\n",
    "                        var=expression_quantified.var.copy(),\n",
    "                        obs=newObs)\n",
    "pseudobulk.raw = pseudobulk.copy()\n",
    "                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3c33909-1e4d-418d-96af-92e724548187",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for condition in set(pseudobulk.obs.condition):\n",
    "    subset = pseudobulk[pseudobulk.obs.condition == condition].copy()\n",
    "    sc.pp.normalize_total(subset)\n",
    "    sc.pp.log1p(subset)\n",
    "    subset.obs[\"regimes\"] = np.unique(subset.obs.targets, return_inverse=True)[1]    \n",
    "    print(f\"{condition:>15} v3 ends up with {subset.n_obs:>6} instances and {subset.n_vars:>5} genes.\")\n",
    "    subset.obs[\"spearmanCorr\"]          = 0.0\n",
    "    subset.uns[\"perturbations_overlap\"] = True\n",
    "    subset.obs[\"perturbation_type\"]     = \"knockout\" \n",
    "    subset.obs[\"expression_level_after_perturbation\"] = [\",\".join([\"0\"]*len(targets.split(\",\"))) for targets in subset.obs[\"perturbation\"] ]\n",
    "    subset.obs.loc[(subset.obs.is_control),          # All instances' perturbations should be measured\n",
    "                   \"expression_level_after_perturbation\"] = np.nan\n",
    "\n",
    "    perturbed_genes = set.union(*[set(p.split(\",\")) for p in subset.obs[\"perturbation\"]])\n",
    "    perturbed_and_measured_genes = perturbed_genes.intersection(subset.var.index)\n",
    "    perturbed_but_not_measured_genes = perturbed_genes.difference(subset.var.index)\n",
    "    subset.uns[\"perturbed_and_measured_genes\"]     = list(perturbed_and_measured_genes)\n",
    "    subset.uns[\"perturbed_but_not_measured_genes\"] = list(perturbed_but_not_measured_genes)\n",
    "\n",
    "    os.makedirs(f\"perturbations/{dataset_name}_{condition}_v3\", exist_ok=True)\n",
    "    subset.write_h5ad(f\"perturbations/{dataset_name}_{condition}_v3/test.h5ad\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "3778fe49-5cef-4a99-85e1-14cc5b91bcd8",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Check Consistency w/ Perturbation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "161ab7c7-1568-4202-a8eb-084abfc5ae2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "pseudobulks = [\n",
    "    pseudobulk[pseudobulk.obs.condition == i].copy()\n",
    "    for i in set(pseudobulk.obs.condition)]\n",
    "\n",
    "for idx, pb in enumerate(pseudobulks):\n",
    "    print(f\"{pb.obs.condition[0]:>15} condition has {pb.shape[0]} aggregated cells\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bafda7db-6dd3-4841-8734-fe9142ba6857",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# If verbose is set to True, display disconcordant trials and their controls\n",
    "for idx, pb in enumerate(pseudobulks):\n",
    "    status, logFC = ingestion.checkConsistency(pb, \n",
    "                                               perturbationType=\"knockdown\", \n",
    "                                               group=None,\n",
    "                                               verbose=False) \n",
    "    pseudobulks[idx].obs[\"consistentW/Perturbation\"] = status\n",
    "    pseudobulks[idx].obs[\"logFC\"] = logFC\n",
    "    print(Counter(status))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "5bbaa836-489d-4052-aa5c-c17e27c29bff",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Check Consistency between replications"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74312e6b-7977-4226-8b7c-138b22b66f45",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for idx, pb in enumerate(pseudobulks):\n",
    "    correlations = ingestion.computeCorrelation(pb, verbose=True)\n",
    "    pseudobulks[idx].obs[\"spearmanCorr\"] = correlations[0]\n",
    "    pseudobulks[idx].obs[\" pearsonCorr\"] = correlations[1]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "caed96cc-a562-402f-83fd-264ca6915d0d",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Compute the Magnitude of Perturbation Effect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7c18caa-8750-4f6d-82cc-22f3d6869717",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Downloaded from http://humantfs.ccbr.utoronto.ca/download.php \"\"\"\n",
    "TFList = pd.read_csv(humanTFPath, index_col=0).iloc[:, [1,3]]\n",
    "TFDict = dict([tuple(i) for i in TFList.to_numpy().tolist() if i[1] == 'Yes'])\n",
    "\n",
    "\"\"\"\n",
    "Downloaded from https://epifactors.autosome.org/description \"\"\"\n",
    "EpiList = pd.read_csv(humanEpiPath, index_col=0).iloc[:, [0,14]]\n",
    "EpiDict = dict([tuple(i) for i in EpiList.to_numpy().tolist()])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "362895e3",
   "metadata": {},
   "source": [
    "### The plot for the figure\n",
    "\n",
    "The below chunk is the figure we use in the manuscript."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24558776-51c7-44bf-83a0-8de77e328bd7",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "\"\"\" If want to look at bigness on TF only \"\"\"\n",
    "for idx, pb in enumerate(pseudobulks):\n",
    "    print(pb.obs.condition[0])\n",
    "    TFVar = [i for i,p in enumerate(pb.var.index) if p in TFDict or p in EpiDict]\n",
    "    pseudobulkTFOnly = pb[:, TFVar].copy()\n",
    "    \n",
    "    ingestion.quantifyEffect(adata=pseudobulkTFOnly, \n",
    "                             fname=perturbEffectTFOnlyPath.split(\".csv\")[0] + pb.obs.condition[0] + \".csv\", \n",
    "                             group=None, \n",
    "                             diffExprFC=False, \n",
    "                             withDEG=False,\n",
    "                             prefix=\"TFOnly\")\n",
    "    \n",
    "    ingestion.quantifyEffect(adata=pb, \n",
    "                             fname=perturbEffectFullTranscriptomePath.split(\".csv\")[0] + pb.obs.condition[0] + \".csv\", \n",
    "                             group=None,\n",
    "                             diffExprFC=False, \n",
    "                             withDEG=False,\n",
    "                             prefix=\"\")\n",
    "\n",
    "    listOfMetrics = [\"MI\", \"logFCMean\", \"logFCNorm2\", \"logFCMedian\"]\n",
    "    for m in listOfMetrics:\n",
    "        pseudobulks[idx].obs[f\"TFOnly{m}\"] = pseudobulkTFOnly.obs[f\"TFOnly{m}\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b39f8b8e-6a52-4edf-8202-800196b57f4b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for idx, pb in enumerate(pseudobulks):\n",
    "    print(pb.obs.condition[0])\n",
    "    metricOfInterest = [\"logFCMean\", \"logFCNorm2\", \"logFCMedian\", \n",
    "                        \"TFOnlylogFCMean\", \"TFOnlylogFCNorm2\", \"TFOnlylogFCMedian\"]\n",
    "    ingestion.checkPerturbationEffectMetricCorrelation(pb, metrics=metricOfInterest)\n",
    "    ingestion.visualizePerturbationEffect(pb, metrics=metricOfInterest, TFDict=TFDict, EpiDict=EpiDict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7feacbe1-0175-4554-acbe-cf80dff541a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx, pb in enumerate(pseudobulks):\n",
    "    sc.pp.calculate_qc_metrics(pb, log1p=False, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "313650e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx, pb in enumerate(pseudobulks):\n",
    "    print(pb.obs[\"condition\"][0])\n",
    "    ingestion.visualizePerturbationMetadata(pb[pb.obs[\"spearmanCorr\"] != -999], \n",
    "                                            x=\"spearmanCorr\", \n",
    "                                            y=\"logFC\", \n",
    "                                            style=\"consistentW/Perturbation\", \n",
    "                                            hue=\"logFCNorm2\", \n",
    "                                            markers=['o', '^', 'X'])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "345b2c1b-c355-4843-bb10-fdbae1baf665",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Basic EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b45934a0-21e5-435a-8a8e-e070d10fa593",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for idx, pb in enumerate(pseudobulks):\n",
    "    print(pb.obs.condition[0])\n",
    "    sc.pp.calculate_qc_metrics(pb, log1p=False, inplace=True)\n",
    "    sc.pp.log1p(pb)\n",
    "    sc.pp.highly_variable_genes(pb, min_mean=0.2, max_mean=4, min_disp=0.2, n_bins=50)\n",
    "    with warnings.catch_warnings():\n",
    "        sc.tl.pca(pb, n_comps=100)\n",
    "    sc.pp.neighbors(pb)\n",
    "    sc.tl.umap(pb)\n",
    "    clusterResolutions = []\n",
    "    sc.tl.louvain(pb)\n",
    "    cc_genes = pd.read_csv(cellCyclePath, header = None)[0]\n",
    "    sc.tl.score_genes_cell_cycle(pb, s_genes=cc_genes[:43], g2m_genes=cc_genes[43:])\n",
    "    plt.rcParams['figure.figsize'] = [6, 4.5]\n",
    "    sc.pl.umap(pb, color = [\n",
    "        \"GAPDH\",\n",
    "        \"louvain\", \n",
    "        \"is_control_int\",\n",
    "        \"n_genes_by_counts\",\n",
    "        \"total_counts\",\n",
    "        'S_score',\n",
    "        'G2M_score', \n",
    "        'phase', \n",
    "        'pct_counts_in_top_50_genes', \n",
    "        \"DEG\",\n",
    "    ])\n",
    "    display(pb.obs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83db78fb-86ad-4221-a4b4-23d0a11fd04b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ggrn",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "vscode": {
   "interpreter": {
    "hash": "6b5a871593435beb6782bba9d81972cd2c81bf4313a5d3d604c15e93a1754f0c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
